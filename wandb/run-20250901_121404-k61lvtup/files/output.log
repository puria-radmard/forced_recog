Logged run to: results_and_data/results/e1_temperature_comparison/llama_3_forward_training_test/train/forwardsft_runs.txt
Loading model: meta-llama/Llama-3.1-8B-Instruct
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.39s/it]
Loading SFT training data...
Loading results_and_data/results/e1_temperature_comparison/llama_3_forward_training_test/train/model_summaries/T0.0_trial0_styleeconomist.csv
Found 1 trial files
Combined data: 850 training examples from 1 trials
Loaded 850 training examples
Creating training pairs...
Creating training pairs: 100%|████████████████████████████████████████████████████████████████████| 850/850 [00:00<00:00, 6862.65it/s]
Setting up LoRA...
LoRA model setup complete. Trainable parameters: 6815744
Starting training: 3 epochs, 850 examples, batch size 1

Epoch 1/3
Epoch 1:   6%|█████                                                                                  | 49/850 [00:30<07:26,  1.79it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpb5outx_p/adapter)... Done. 0.5s
Step 50: Loss = 0.4613, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_50
Epoch 1:  12%|██████████▏                                                                            | 99/850 [00:58<07:28,  1.68it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp1z17ye4t/adapter)... Done. 0.4s
Step 100: Loss = 0.4935, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_100
Epoch 1:  18%|███████████████                                                                       | 149/850 [01:28<05:46,  2.03it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpxl37oc0x/adapter)... Done. 0.4s
Step 150: Loss = 0.5225, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_150
Epoch 1:  23%|████████████████████▏                                                                 | 199/850 [01:57<05:39,  1.92it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp0dfpisf5/adapter)... Done. 0.4s
Step 200: Loss = 0.4470, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_200
Epoch 1:  29%|█████████████████████████▏                                                            | 249/850 [02:28<06:58,  1.44it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp298jljb4/adapter)... Done. 0.4s
Step 250: Loss = 0.5137, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_250
Epoch 1:  35%|██████████████████████████████▎                                                       | 299/850 [03:00<05:31,  1.66it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpli4nkj8r/adapter)... Done. 0.4s
Step 300: Loss = 0.4939, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_300
Epoch 1:  41%|███████████████████████████████████▎                                                  | 349/850 [03:28<05:21,  1.56it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmprlmqu0ab/adapter)... Done. 0.4s
Step 350: Loss = 0.4651, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_350
Epoch 1:  47%|████████████████████████████████████████▎                                             | 399/850 [03:58<04:06,  1.83it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp779qtyi3/adapter)... Done. 0.4s
Step 400: Loss = 0.5649, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_400
Epoch 1:  53%|█████████████████████████████████████████████▍                                        | 449/850 [04:28<03:37,  1.85it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmps4vuk42w/adapter)... Done. 0.4s
Step 450: Loss = 0.6162, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_450
Epoch 1:  59%|██████████████████████████████████████████████████▍                                   | 499/850 [04:56<02:35,  2.26it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpq6ejhmvy/adapter)... Done. 0.4s
Step 500: Loss = 0.7188, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_500
Epoch 1:  65%|███████████████████████████████████████████████████████▌                              | 549/850 [05:24<02:50,  1.76it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpxsj2acg7/adapter)... Done. 0.4s
Step 550: Loss = 0.4913, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_550
Epoch 1:  70%|████████████████████████████████████████████████████████████▌                         | 599/850 [05:54<02:11,  1.92it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpzxakkk0e/adapter)... Done. 0.4s
Step 600: Loss = 0.5977, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_600
Epoch 1:  76%|█████████████████████████████████████████████████████████████████▋                    | 649/850 [06:22<01:59,  1.69it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpxmviueib/adapter)... Done. 0.4s
Step 650: Loss = 0.5484, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_650
Epoch 1:  82%|██████████████████████████████████████████████████████████████████████▋               | 699/850 [06:53<01:24,  1.79it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpetovk42b/adapter)... Done. 0.4s
Step 700: Loss = 0.4665, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_700
Epoch 1:  88%|███████████████████████████████████████████████████████████████████████████▊          | 749/850 [07:21<00:47,  2.11it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp8c0eeto9/adapter)... Done. 0.4s
Step 750: Loss = 0.6911, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_750
Epoch 1:  94%|████████████████████████████████████████████████████████████████████████████████▊     | 799/850 [07:52<00:34,  1.47it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpw8lkd2wh/adapter)... Done. 0.4s
Step 800: Loss = 0.6522, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_800
Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████▉| 849/850 [08:20<00:00,  1.83it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpflofr5b2/adapter)... Done. 0.5s
Step 850: Loss = 0.5216, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_850
Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████| 850/850 [08:22<00:00,  1.69it/s]
Epoch 1 complete. Average loss: nan

Epoch 2/3
Epoch 2:   6%|█████                                                                                  | 49/850 [00:27<08:14,  1.62it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp8yxmchfd/adapter)... Done. 0.5s
Step 900: Loss = 0.3317, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_900
Epoch 2:  12%|██████████▏                                                                            | 99/850 [00:57<08:43,  1.43it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpkuwk6vbc/adapter)... Done. 0.5s
Step 950: Loss = 0.1255, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_950
Epoch 2:  18%|███████████████                                                                       | 149/850 [01:27<05:57,  1.96it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp8bfess7g/adapter)... Done. 0.4s
Step 1000: Loss = 0.4638, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1000
Epoch 2:  23%|████████████████████▏                                                                 | 199/850 [01:57<06:04,  1.79it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmppc66ngdr/adapter)... Done. 0.4s
Step 1050: Loss = 0.2406, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1050
Epoch 2:  29%|█████████████████████████▏                                                            | 249/850 [02:27<05:38,  1.78it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmppgklrt0k/adapter)... Done. 0.4s
Step 1100: Loss = 0.4040, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1100
Epoch 2:  35%|██████████████████████████████▎                                                       | 299/850 [02:56<05:40,  1.62it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpseg_gufd/adapter)... Done. 0.4s
Step 1150: Loss = 0.1994, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1150
Epoch 2:  41%|███████████████████████████████████▎                                                  | 349/850 [03:26<06:01,  1.39it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp3hz3bb11/adapter)... Done. 0.4s
Step 1200: Loss = 0.3881, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1200
Epoch 2:  47%|████████████████████████████████████████▎                                             | 399/850 [03:56<05:11,  1.45it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpf__yehle/adapter)... Done. 0.4s
Step 1250: Loss = 0.1091, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1250
Epoch 2:  53%|█████████████████████████████████████████████▍                                        | 449/850 [04:25<03:07,  2.14it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp_m7u5run/adapter)... Done. 0.4s
Step 1300: Loss = 0.2928, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1300
Epoch 2:  59%|██████████████████████████████████████████████████▍                                   | 499/850 [04:54<03:08,  1.87it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp9he0e3a5/adapter)... Done. 0.4s
Step 1350: Loss = 0.3214, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1350
Epoch 2:  65%|███████████████████████████████████████████████████████▌                              | 549/850 [05:25<02:28,  2.03it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpgnxng7hl/adapter)... Done. 0.4s
Step 1400: Loss = 0.2948, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1400
Epoch 2:  70%|████████████████████████████████████████████████████████████▌                         | 599/850 [05:55<02:33,  1.64it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmps__dwirz/adapter)... Done. 0.4s
Step 1450: Loss = 0.3376, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1450
Epoch 2:  76%|█████████████████████████████████████████████████████████████████▋                    | 649/850 [06:26<01:54,  1.75it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpfnjris1u/adapter)... Done. 0.4s
Step 1500: Loss = 0.3595, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1500
Epoch 2:  82%|██████████████████████████████████████████████████████████████████████▋               | 699/850 [06:54<01:16,  1.96it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpdnd5fv7e/adapter)... Done. 0.5s
Step 1550: Loss = 0.4249, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1550
Epoch 2:  88%|███████████████████████████████████████████████████████████████████████████▊          | 749/850 [07:22<00:56,  1.80it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpmug7vyqx/adapter)... Done. 0.4s
Step 1600: Loss = 0.4460, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1600
Epoch 2:  94%|████████████████████████████████████████████████████████████████████████████████▊     | 799/850 [07:54<00:26,  1.95it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpuhvl_l2v/adapter)... Done. 0.4s
Step 1650: Loss = 0.4202, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1650
Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████▉| 849/850 [08:23<00:00,  1.59it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp13_sahuc/adapter)... Done. 0.4s
Step 1700: Loss = 0.1980, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1700
Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████| 850/850 [08:25<00:00,  1.68it/s]
Epoch 2 complete. Average loss: nan

Epoch 3/3
Epoch 3:   6%|█████                                                                                  | 49/850 [00:29<10:57,  1.22it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmppod8cpck/adapter)... Done. 0.4s
Step 1750: Loss = 0.1835, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1750
Epoch 3:  12%|██████████▏                                                                            | 99/850 [00:59<06:11,  2.02it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpzyaz8fm7/adapter)... Done. 0.4s
Step 1800: Loss = 0.2537, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1800
Epoch 3:  18%|███████████████                                                                       | 149/850 [01:31<07:00,  1.67it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpc3bcmybh/adapter)... Done. 0.4s
Step 1850: Loss = 0.1556, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1850
Epoch 3:  23%|████████████████████▏                                                                 | 199/850 [02:04<08:24,  1.29it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpuovs34r1/adapter)... Done. 0.4s
Step 1900: Loss = 0.3250, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1900
Epoch 3:  29%|█████████████████████████▏                                                            | 249/850 [02:33<05:32,  1.81it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp22wvpphc/adapter)... Done. 0.4s
Step 1950: Loss = 0.4110, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_1950
Epoch 3:  35%|██████████████████████████████▎                                                       | 299/850 [03:03<05:03,  1.81it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp7b2bj98v/adapter)... Done. 0.4s
Step 2000: Loss = 0.1564, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2000
Epoch 3:  41%|███████████████████████████████████▎                                                  | 349/850 [03:30<04:51,  1.72it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpz3d92s98/adapter)... Done. 0.4s
Step 2050: Loss = 0.3201, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2050
Epoch 3:  47%|████████████████████████████████████████▎                                             | 399/850 [04:00<04:18,  1.74it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpso2ej0ag/adapter)... Done. 0.4s
Step 2100: Loss = 0.1500, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2100
Epoch 3:  53%|█████████████████████████████████████████████▍                                        | 449/850 [04:30<04:17,  1.56it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpk5dtfasa/adapter)... Done. 0.4s
Step 2150: Loss = 0.1383, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2150
Epoch 3:  59%|██████████████████████████████████████████████████▍                                   | 499/850 [05:01<03:36,  1.62it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpfu7exgqp/adapter)... Done. 0.4s
Step 2200: Loss = 0.1938, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2200
Epoch 3:  65%|███████████████████████████████████████████████████████▌                              | 549/850 [05:31<02:34,  1.95it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpu80qkyhq/adapter)... Done. 0.4s
Step 2250: Loss = 0.2000, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2250
Epoch 3:  70%|████████████████████████████████████████████████████████████▌                         | 599/850 [06:01<02:18,  1.82it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp7q5nepwx/adapter)... Done. 0.4s
Step 2300: Loss = 0.2333, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2300
Epoch 3:  76%|█████████████████████████████████████████████████████████████████▋                    | 649/850 [06:30<01:33,  2.16it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpyixv5ecf/adapter)... Done. 0.4s
Step 2350: Loss = 0.3288, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2350
Epoch 3:  82%|██████████████████████████████████████████████████████████████████████▋               | 699/850 [06:56<01:08,  2.22it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp3wz8a5ma/adapter)... Done. 0.4s
Step 2400: Loss = 0.5334, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2400
Epoch 3:  88%|███████████████████████████████████████████████████████████████████████████▊          | 749/850 [07:25<00:53,  1.88it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpiarxzfu6/adapter)... Done. 0.4s
Step 2450: Loss = 0.2677, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2450
Epoch 3:  94%|████████████████████████████████████████████████████████████████████████████████▊     | 799/850 [07:54<00:28,  1.76it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmppldetvp0/adapter)... Done. 0.4s
Step 2500: Loss = 0.3643, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2500
Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████████████████▉| 849/850 [08:22<00:00,  1.50it/s][34m[1mwandb[0m: Adding directory to artifact (/tmp/tmp3xuvu0cw/adapter)... Done. 0.4s
Step 2550: Loss = 0.2109, Avg Loss = nan
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2550
Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████| 850/850 [08:25<00:00,  1.68it/s]
Epoch 3 complete. Average loss: nan
Training complete! Saving final adapters...
[34m[1mwandb[0m: Adding directory to artifact (/tmp/tmpuj8gbmi6/adapter)... Done. 0.4s
Logged LoRA adapters artifact: llama_3_forward_training_test_forwardsft_temp0.0_styleeconomist_20250901_121404.lora_adapters_step_2550
Total steps: 2550
Final average loss: nan
